---
title: "Structural Topic Modeling of the Anger Narratives"
author: "Pooya Razavi"
date: "2022-12-06"
output: html_document
editor_options: 
  chunk_output_type: console
---



```{r setup, include=FALSE, warning=FALSE}
#load libraries
package_list <- c("dplyr", "tidyr", "ggplot2", "tidytext", "topicmodels", "stm")
lapply(package_list, require, character.only = TRUE)


df <- readxl::read_xlsx("C:/Users/pooya/Dropbox (University of Oregon)/Anger Dissertation/Prototype study analysis/ProcessedData_F21_W22_S22_F22.xlsx")

knitr::opts_chunk$set(echo = TRUE)
```


# Pre-processing

```{r ingest}
 #apply the preregistered data exclusion
    #assigning values to factor levels
      df$NarrativeWritten <- as.factor(df$NarrativeWritten)
      df$NarrativeRelevant <- as.factor(df$NarrativeRelevant)
      df$Condition <- as.factor(df$Condition)
      
      levels(df$NarrativeWritten) <- c("No", "Yes")
      levels(df$NarrativeRelevant) <- c("No", "Yes", NA, NA) 
      levels(df$Condition) <- c("justified", "nonjustified", NA)
    
    #drop cases following preregistration
      df1 <- df %>% 
        filter(NarrativeWritten != "No") %>% 
        filter(NarrativeRelevant != "No") %>% 
        filter(!is.na(Condition))
      
 
  #keep the relevant variables and drop the rest
      df_stm <- df1 %>% 
        mutate(all_narratives = dplyr::coalesce(right_narrative, nonright_narrative)) %>% 
        select(ResponseId, Condition, all_narratives)
      

```


```{r preprocessing-5threshold}
#stemming, dropping punctuation, numbers, and stop words
  processed <- textProcessor(df_stm$all_narratives, metadata = df_stm) 

#evaluate how many words and documents would be removed from the data set at each word threshold
  plotRemoved(processed$documents, lower.thresh = seq(1, 20, by = 1))
  
#saving the different parts of the processed data
  out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 5) #including words that appear in at least 5 documents
  docs <- out$documents
  vocab <- out$vocab
  meta <- out$meta

```

## Determining the Optimal K

```{r}
#Method: using the searchK algorithm
  set.seed(110)
  storage <- searchK(out$documents, out$vocab, K = c(2:40), prevalence = ~Condition, data = meta, seed = 110)
    #this warning was produced: "K=2 is equivalent to a unidimensional scaling model which you may prefer."
  
  plot(storage) #looks like 9, 11, and 14 topics are good candidates (when lowerthreshold = 5)


```

## STM Estimation (lower threshold set as 5)


```{r model-est}
#model with 7 topics
anger_fit_7t <- stm(documents = out$documents, vocab = out$vocab, K = 7, prevalence = ~Condition, max.em.its = 75, data = out$meta, init.type = "Spectral", seed = 110)

#model with 9 topics
anger_fit_9t <- stm(documents = out$documents, vocab = out$vocab, K = 9, prevalence = ~Condition, max.em.its = 75, data = out$meta, init.type = "Spectral", seed = 110)

#model with 11 topics
anger_fit_11t <- stm(documents = out$documents, vocab = out$vocab, K = 11, prevalence = ~Condition, max.em.its = 75, data = out$meta, init.type = "Spectral", seed = 110)

#model with 14 topics
anger_fit_14t <- stm(documents = out$documents, vocab = out$vocab, K = 14, prevalence = ~Condition, max.em.its = 75, data = out$meta, init.type = "Spectral", seed = 110)

#model with 16 topics
anger_fit_16t <- stm(documents = out$documents, vocab = out$vocab, K = 16, prevalence = ~Condition, max.em.its = 75, data = out$meta, init.type = "Spectral", seed = 110)

#model with 25 topics
anger_fit_25t <- stm(documents = out$documents, vocab = out$vocab, K = 25, prevalence = ~Condition, max.em.its = 75, data = out$meta, init.type = "Spectral", seed = 110)

```


### Explore the topics

9 Topics

```{r}

#Internal Plot
plot(anger_fit_9t, n = 7)
plot.STM(anger_fit_9t, type = "summary", n = 7, labeltype = "frex")

####Plot using ggplot
#get the expected proportions for each topic
exp_proportionas_9t <- make.dt(anger_fit_9t) %>% 
                          summarise_all(mean) %>% 
                            t() %>% as.data.frame() %>% 
                            tibble::rownames_to_column("Topic") %>% 
                            filter(Topic != "docnum")
#get the top word list
exp_proportionas_9t <- exp_proportionas_9t %>% 
                            cbind((labelTopics(anger_fit_9t, c(1:9), n = 7))[["frex"]])

#attach it to the proportions df
top_words <- paste(exp_proportionas_9t$`1`, exp_proportionas_9t$`2`,
                                                     exp_proportionas_9t$`3`, exp_proportionas_9t$`4`,
                                                     exp_proportionas_9t$`5`, exp_proportionas_9t$`6`,
                                                     exp_proportionas_9t$`7`, sep = ", ")

exp_proportionas_9t <- exp_proportionas_9t %>% 
                            mutate(top_words = top_words)

#ggplot
exp_proportionas_9t %>% 
  ggplot(., aes(x = reorder(Topic, V1), y = V1, label = top_words, fill = Topic)) +
    geom_col(show.legend = FALSE) +
    geom_text(hjust = 0, nudge_y = 0.002, size = 4,
              family = "serif") +
    coord_flip() +
    scale_y_continuous(expand = c(0,0),
                       limits = c(0, 0.30),
                       labels = scales::percent_format())  +
  ggthemes::theme_tufte(base_family = "serif", ticks = FALSE) +
      theme(plot.title = element_text(size = 16,
                                      family="serif"),
        plot.subtitle = element_text(size = 13)) +
  labs(x = NULL, y = "Expected Topic Prevalence",
       title = "Topic Prevalence Across All Narratives",
       subtitle = "With the top seven words (using FREX algorithm) that contribute to each topic")
```

Making a function based on the code above

```{r}
stm_plot <- function(model_name) {
  
  #get the expected proportions for each topic
    exp_proportions <- make.dt(model_name) %>% 
                              summarise_all(mean) %>% 
                                t() %>% as.data.frame() %>% 
                                tibble::rownames_to_column("Topic") %>% 
                                filter(Topic != "docnum")
    #number of topics
    t_number <- nrow(exp_proportions)
    
    #get the top word list
    exp_proportions <- exp_proportions %>% 
                                cbind((labelTopics(model_name, c(1:t_number), n = 7))[["frex"]])
    
    #attach it to the proportions df
    top_words <- paste(exp_proportions$`1`, exp_proportions$`2`,
                        exp_proportions$`3`, exp_proportions$`4`,
                        exp_proportions$`5`, exp_proportions$`6`,
                        exp_proportions$`7`, sep = ", ")
    
    exp_proportions <- exp_proportions %>% 
                                mutate(top_words = top_words)
    
    #ggplot
    exp_proportions %>% 
      ggplot(., aes(x = reorder(Topic, V1), y = V1, label = top_words, fill = Topic)) +
        geom_col(show.legend = FALSE) +
        geom_text(hjust = 0, nudge_y = 0.002, size = 4,
                  family = "serif") +
        coord_flip() +
        scale_y_continuous(expand = c(0,0),
                           limits = c(0, 0.30),
                           labels = scales::percent_format())  +
      ggthemes::theme_tufte(base_family = "serif", ticks = FALSE) +
      theme(plot.title = element_text(size = 16,
                                      family="serif"),
            plot.subtitle = element_text(size = 13)) +
      labs(x = NULL, y = "Expected Topic Prevalence",
           title = paste0("Topic Prevalence Across All Narratives (", t_number, " Topics)"),
           subtitle = "With the top seven words (using FREX algorithm) that contribute to each topic")
  
  
}


```

Exploring other models (7-, 11-, 14-, and 25-topics)

```{r}
#7 topics
stm_plot(anger_fit_7t)

#11 topics
plot(anger_fit_11t, n = 7)
plot.STM(anger_fit_11t, type = "summary", n = 7, labeltype = "frex")
stm_plot(anger_fit_11t)

##14 topics
plot(anger_fit_14t, n = 7)
plot.STM(anger_fit_14t, type = "summary", n = 7, labeltype = "frex")
stm_plot(anger_fit_14t)

##16 topics
stm_plot(anger_fit_16t)

##25 topics
stm_plot(anger_fit_25t)


```


```{r}
#look at collections of words that are associated with topics
  labels_9t <- labelTopics(anger_fit_9t, c(1:9), n = 10)
  labels_11t <- labelTopics(anger_fit_11t, c(1:11), n = 10)
  labels_14t <- labelTopics(anger_fit_14t, c(1:14), n = 10)

  par(mfrow = c(1, 1))

  #Plotting highest probable words
  png(file="topic_words_9t.png", width=1100, height=500)
  par(mfrow = c(1, 2))
  plot(anger_fit_9t, type = "labels", topics = 1:5, labeltype = "frex", n = 10)
  plot(anger_fit_9t, type = "labels", topics = 6:9, labeltype = "frex", n = 10)
  dev.off()
  
  png(file="topic_words_11t.png", width=1100, height=500)
  par(mfrow = c(1, 2))
  plot(anger_fit_11t, type = "labels", topics = 1:6, labeltype = "frex", n = 10)
  plot(anger_fit_11t, type = "labels", topics = 7:11, labeltype = "frex", n = 10)
  dev.off()
  
  png(file="topic_words_14t.png", width=1100, height=500)
  par(mfrow = c(1, 2))
  plot(anger_fit_14t, type = "labels", topics = 1:7, labeltype = "frex", n = 10)
  plot(anger_fit_14t, type = "labels", topics = 8:14, labeltype = "frex", n = 10)
  dev.off()
  
  #Possibly more interpretable: the LIFT method
  cbind(paste("topic", 1:9), labels_9t[["lift"]]) %>% knitr::kable() %>% kableExtra::kable_styling()
  cbind(paste("topic", 1:11), labels_11t[["lift"]]) %>% knitr::kable() %>% kableExtra::kable_styling()
  cbind(paste("topic", 1:14), labels_15t[["lift"]]) %>% knitr::kable() %>% kableExtra::kable_styling()

  #topic quality
  topicQuality(model = anger_fit_9t, documents = out$documents)
  topicQuality(model = anger_fit_11t, documents = out$documents)
  topicQuality(model = anger_fit_14t, documents = out$documents)
  
#a few examples of examining documents that are highly associated with topics
  example_topic1 <- findThoughts(anger_fit_9t, texts = meta$all_narratives, n = 3, topics = 1)$docs[[1]]
  example_topic2 <- findThoughts(anger_fit_9t, texts = meta$all_narratives, n = 3, topics = 2)$docs[[1]]
  example_topic3 <- findThoughts(anger_fit_9t, texts = meta$all_narratives, n = 3, topics = 3)$docs[[1]]
  example_topic4 <- findThoughts(anger_fit_9t, texts = meta$all_narratives, n = 3, topics = 4)$docs[[1]]
  example_topic5 <- findThoughts(anger_fit_9t, texts = meta$all_narratives, n = 3, topics = 5)$docs[[1]] #needs more investigation
  example_topic6 <- findThoughts(anger_fit_9t, texts = meta$all_narratives, n = 3, topics = 6)$docs[[1]]
  example_topic7 <- findThoughts(anger_fit_9t, texts = meta$all_narratives, n = 3, topics = 7)$docs[[1]]
  example_topic8 <- findThoughts(anger_fit_9t, texts = meta$all_narratives, n = 3, topics = 8)$docs[[1]]#needs more investigation
  example_topic9 <- findThoughts(anger_fit_9t, texts = meta$all_narratives, n = 3, topics = 9)$docs[[1]]#needs more investigation
  
  example_topic1
  example_topic2
  example_topic3
  example_topic4
  example_topic5
  example_topic6
  example_topic7
  example_topic8
  example_topic9
  
  par(mfrow = c(1, 2), mar = c(0.5, 0.5, 1, 0.5))
  plotQuote(example_topic1, width = 30, main = "Topic 6")
  plotQuote(example_topic2, width = 30, main = "Topic 18")
  
#topic correlations
  topic_correlation<-topicCorr(anger_fit_9t)
  plot(topic_correlation)
```

## Estimate Covariate Relation

```{r}
out$meta$Condition <- as.factor(out$meta$Condition)

#7-topic model
prep_7t <- estimateEffect(formula = 1:7 ~ Condition, anger_fit_7t, meta = out$meta, uncertainty = "Global")
summary(prep_7t, topics = c(1:7))

#9-topic model
prep_9t <- estimateEffect(1:9 ~ Condition, anger_fit_9t, meta = out$meta, uncertainty = "Global")
summary(prep_9t, topics = c(1:9))

#11-topic model
prep_11t <- estimateEffect(1:11 ~ Condition, anger_fit_11t, meta = out$meta, uncertainty = "Global")
summary(prep_11t, topics = c(1:11))

#16-topic model
prep_16t <- estimateEffect(1:16 ~ Condition, anger_fit_16t, meta = out$meta, uncertainty = "Global")
summary(prep_16t, topics = c(1:16))

#25-topic model
prep_25t <- estimateEffect(1:25 ~ Condition, anger_fit_25t, meta = out$meta, uncertainty = "Global")


#function to report the comparisons in a more organized way (in a single table)
report_stm_cov_effect <- function(prepped_model) {
      
      model_results <- data.frame(Topic = NA,
                                  Var = NA,
                                  Estimate = NA,
                                  SE = NA,
                                  t = NA,
                                  p = NA)
      t_number <- max(prepped_model[["topics"]])
      
      for(topic in 1:t_number){
        print(topic)
        
        topic_summary <- (summary(prepped_model, topics = topic))[["tables"]] %>% 
                              as.data.frame() %>% 
                              tibble::rownames_to_column("Var")
        
        colnames(topic_summary) <- c("Var", "Estimate", "SE", "t", "p")
        Topic <- c(topic, topic)
        topic_summary <- cbind(Topic, topic_summary)
        
        model_results <- rbind(model_results, topic_summary)
      }
      
      model_results[-1,] %>% knitr::kable(digits = 3) %>% kableExtra::kable_styling()

}

report_stm_cov_effect(prep_7t)
report_stm_cov_effect(prep_11t)
report_stm_cov_effect(prep_16t)
report_stm_cov_effect(prep_25t)

```


# STM Estimation (lower threshold set as 5)

```{r preprocessing-10threshold}
#stemming, dropping punctuation, numbers, and stop words
  processed <- textProcessor(df_stm$all_narratives, metadata = df_stm) 


#saving the different parts of the processed data
  out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 10) #including words that appear in at least 10 documents
  docs <- out$documents
  vocab <- out$vocab
  meta <- out$meta

```

## Determining the Optimal K

```{r}
#Method: using the searchK algorithm
  storage <- searchK(out$documents, out$vocab, K = c(2:20), prevalence = ~Condition, data = meta)
    #this warning was produced: "K=2 is equivalent to a unidimensional scaling model which you may prefer."
  
  plot(storage) #looks like 6 and 10 topics are good candidates (when lowerthreshold = 10)


```


```{r}
#model with 6 topics
anger_fit_6t <- stm(documents = out$documents, vocab = out$vocab, K = 6, prevalence = ~Condition, max.em.its = 75, data = out$meta, init.type = "Spectral")

semanticCoherence(anger_fit_6t, out$documents)
exclusivity(anger_fit_6t, M = 10, frexw = 0.7)

#look at collections of words that are associated with topics
  labels_6t <- labelTopics(anger_fit_6t, c(1:6), n = 10)
    #Possibly more interpretable: using the LIFT method
  cbind(paste("topic", 1:6), labels_6t[["lift"]]) %>% knitr::kable() %>% kableExtra::kable_styling()
  
#topic quality
  topicQuality(model = anger_fit_6t, documents = out$documents)  
  
#a few examples of examining documents that are highly associated with topics
  example_topic1 <- findThoughts(anger_fit_6t, texts = meta$all_narratives, n = 3, topics = 1)$docs[[1]]
  example_topic2 <- findThoughts(anger_fit_6t, texts = meta$all_narratives, n = 3, topics = 2)$docs[[1]]
  example_topic3 <- findThoughts(anger_fit_6t, texts = meta$all_narratives, n = 3, topics = 3)$docs[[1]]
  example_topic4 <- findThoughts(anger_fit_6t, texts = meta$all_narratives, n = 3, topics = 4)$docs[[1]]
  example_topic5 <- findThoughts(anger_fit_6t, texts = meta$all_narratives, n = 3, topics = 5)$docs[[1]] 
  example_topic6 <- findThoughts(anger_fit_6t, texts = meta$all_narratives, n = 3, topics = 6)$docs[[1]]  
  
  
  example_topic1
  example_topic2
  example_topic3
  example_topic4
  example_topic5
  example_topic6
  
#estimate covariate relation    
  out$meta$Condition <- as.factor(out$meta$Condition)
  prep <- estimateEffect(1:6 ~ Condition, anger_fit_6t, meta = out$meta, uncertainty = "Global")
  summary(prep, topics = c(1:6))   


#################################### 
#model with 10 topics
anger_fit_10t <- stm(documents = out$documents, vocab = out$vocab, 
                     K = 10, 
                     prevalence = ~Condition, 
                     max.em.its = 75, data = out$meta, init.type = "Spectral")

semanticCoherence(anger_fit_10t, out$documents)
#exclusivity(anger_fit_10t, M = 10, frexw = 0.7)

#look at collections of words that are associated with topics
  labels_10t <- labelTopics(anger_fit_10t, c(1:10), n = 10)
    #Possibly more interpretable: using the LIFT method
  cbind(paste("topic", 1:10), labels_10t[["lift"]]) %>% knitr::kable() %>% kableExtra::kable_styling()
  
#topic quality
  topicQuality(model = anger_fit_10t, documents = out$documents)  
  
#a few examples of examining documents that are highly associated with topics
  example_topic1 <- findThoughts(anger_fit_10t, texts = meta$all_narratives, n = 3, topics = 1)$docs[[1]]
  example_topic2 <- findThoughts(anger_fit_10t, texts = meta$all_narratives, n = 3, topics = 2)$docs[[1]]
  example_topic3 <- findThoughts(anger_fit_10t, texts = meta$all_narratives, n = 3, topics = 3)$docs[[1]]
  example_topic4 <- findThoughts(anger_fit_10t, texts = meta$all_narratives, n = 3, topics = 4)$docs[[1]]
  example_topic5 <- findThoughts(anger_fit_10t, texts = meta$all_narratives, n = 3, topics = 5)$docs[[1]] 
  example_topic6 <- findThoughts(anger_fit_10t, texts = meta$all_narratives, n = 3, topics = 6)$docs[[1]] 
  example_topic7 <- findThoughts(anger_fit_10t, texts = meta$all_narratives, n = 3, topics = 7)$docs[[1]] 
  example_topic8 <- findThoughts(anger_fit_10t, texts = meta$all_narratives, n = 3, topics = 8)$docs[[1]] 
  example_topic9 <- findThoughts(anger_fit_10t, texts = meta$all_narratives, n = 3, topics = 9)$docs[[1]] 
  example_topic10 <- findThoughts(anger_fit_10t, texts = meta$all_narratives, n = 3, topics = 10)$docs[[1]] 

  example_topic1
  example_topic2
  example_topic3
  example_topic4
  example_topic5
  example_topic6
  example_topic7
  example_topic8
  example_topic9
  example_topic10

  
#estimate covariate relation    
  out$meta$Condition <- as.factor(out$meta$Condition)
  prep <- estimateEffect(1:10 ~ Condition, anger_fit_10t, meta = out$meta, uncertainty = "Global")
  summary(prep, topics = c(1:10))  
```


```{r}
df_w_stm_11t <- cbind(processed$meta, anger_fit_11t[["theta"]]) 
colnames(df_w_stm_11t)[4:14] <- c(paste0("topic", 1:11))

glimpse(df_w_stm_11t)

df_w_stm_11t %>% 
  select(contains("topic")) %>% 
  psych::describe()


df_w_stm_11t %>% 
  select(Condition, contains("topic")) %>% 
  psych::describeBy(group = df_w_stm_11t$Condition)

df_w_stm_11t %>% 
  group_by(Condition) %>% 
  summarise(across(contains("topic"), mean, na.rm=TRUE))

for (i in 1:11){
  dv_col_number <- i + 3
  
    iv <- df_w_stm_11t$Condition
    dv <- df_w_stm_11t[,dv_col_number]
  
      ttest <- t.test(dv ~ iv)
      effect_size <- effectsize::cohens_d(dv ~ iv, pooled_sd = FALSE)
      t <- ttest[["statistic"]] %>% round(2)
      df <- ttest[["parameter"]] %>% round(1)
      original_p <- ttest[["p.value"]] %>% round(3)
      p <- if_else(original_p >= .001, paste0("= ", as.character(original_p)), "< .001")
      d <- effect_size[1,1] %>% round(2)    
      topic <- (colnames(df_w_stm_11t))[dv_col_number]
      print(paste0(topic, ": t(", df, ") = ", t, ", p ", p, ", d = ", d))

}

par(mfrow = c(4, 3))
df_w_stm_11t_long <- df_w_stm_11t %>% 
                        pivot_longer(cols = contains("topic"),
                                     names_to = "Topic",
                                     values_to = "Theta")

ggplot(df_w_stm_11t_long, aes(x = Theta, fill = Theta)) + 
                geom_histogram(aes(y = ..density..), binwidth = 0.005) +
                geom_density(colour = "lightblue") +
                facet_wrap ( ~ Topic) +
                theme_minimal()

ggplot(df_w_stm_11t_long, aes(x = Theta, fill = Condition)) + 
                geom_histogram(aes(y = ..density..), binwidth = 0.005) +
                #geom_density(alpha = 0.4) +
                facet_wrap ( ~ Topic) +
                xlim(0, 0.4) +
                theme_minimal() +
                theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

